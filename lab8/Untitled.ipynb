{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/datasets/imdb.py:44: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "y_train: \n",
      " [1 0 0 ..., 0 1 0]\n",
      "length y_train:  25000\n",
      "y_test: \n",
      " [1 1 1 ..., 1 0 1]\n",
      "length y_test:  25000\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "X_train: \n",
      " [ [1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      " [1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      " [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n",
      " ...,\n",
      " [1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]\n",
      " [1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]\n",
      " [1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9]]\n",
      "length X_train:  25000\n",
      "X_test: \n",
      " [ [1, 89, 27, 2, 2, 17, 199, 132, 5, 2, 16, 2, 24, 8, 760, 4, 2, 7, 4, 22, 2, 2, 16, 2, 17, 2, 7, 2, 2, 9, 4, 2, 8, 14, 991, 13, 877, 38, 19, 27, 239, 13, 100, 235, 61, 483, 2, 4, 7, 4, 20, 131, 2, 72, 8, 14, 251, 27, 2, 7, 308, 16, 735, 2, 17, 29, 144, 28, 77, 2, 18, 12]\n",
      " [1, 2, 7, 2, 517, 522, 31, 314, 17, 2, 2, 2, 2, 2, 83, 4, 2, 673, 33, 27, 568, 2, 2, 32, 4, 189, 22, 11, 975, 2, 29, 2, 4, 2, 7, 4, 2, 2, 15, 2, 455, 2, 848, 2, 2, 96, 145, 11, 4, 204, 2, 297, 2, 29, 2, 4, 2, 8, 35, 2, 2, 121, 2, 2, 980, 2, 2, 2, 2, 2, 2, 304, 4, 2, 145, 8, 41, 2, 50, 2, 2, 2, 2, 2, 34, 2, 2, 145, 295, 174, 772, 6, 2, 18, 274, 961, 90, 145, 8, 2, 113, 155, 92, 140, 17, 2, 69, 2, 2, 505, 46, 24, 8, 30, 4, 132, 7, 41, 2, 103, 32, 38, 59, 2, 90, 11, 6, 297, 2, 33, 63, 2, 9, 329, 74, 654, 137, 2, 304, 6, 2, 2, 2, 2, 41, 772, 15, 274, 961, 41, 145, 8, 113, 11, 4, 2, 7, 6, 668, 2, 2, 17, 6, 2, 2, 181, 8, 30, 2, 11, 2, 2, 28, 8, 157, 295, 8, 79, 8, 6, 2, 11, 162, 2, 121, 2, 2, 648, 69, 77, 2, 19, 4, 2, 887, 8, 2, 68, 2, 145, 83, 406, 2, 4, 2, 7, 2, 2, 2, 2, 27, 980, 2, 2, 2, 37, 26, 199, 23, 4, 521, 39, 2, 2, 2, 7, 568, 2, 2, 308, 2, 80, 81, 2, 10, 10, 526, 34, 2, 2, 13, 119, 2, 7, 2, 4, 229, 34, 2, 2, 9, 87, 253, 55, 702, 728, 545, 441, 2, 958, 7, 85, 189, 22, 19, 52, 2, 39, 4, 636, 720, 121, 75, 67, 2, 2, 2, 2, 39, 4, 2, 4, 2, 108, 2, 2, 2, 2, 2, 39, 4, 6, 2, 23, 2, 890, 201, 488, 2, 2, 39, 4, 2, 2, 8, 4, 2, 343, 39, 2, 7, 2, 2, 54, 12, 2, 2, 4, 172, 136, 2, 7, 2, 115, 304, 410, 615, 63, 9, 43, 17, 73, 50, 26, 775, 7, 31, 2, 532, 2, 2, 15, 2, 2, 93, 2, 6, 171, 153, 908, 12, 152, 306, 2, 8, 2, 253, 33, 410, 4, 189, 512, 11, 831, 13, 119, 4, 136, 54, 2, 2, 26, 260, 6, 2, 2, 731, 2, 15, 2, 2, 29, 166, 163, 2, 795, 2, 469, 198, 24, 8, 135, 15, 50, 218, 6, 2, 52, 22, 11, 50, 17, 73, 88, 50, 91, 434, 9, 167, 2, 2, 8, 987, 52, 841, 6, 147, 281, 7, 253, 199, 406, 2, 732, 7, 105, 26, 2, 2, 17, 257, 2, 2, 68, 205, 732, 7, 2, 712, 15, 4, 2, 7, 2, 15, 36, 26, 2, 496, 62, 540, 2, 2, 2, 7, 2, 9, 87, 18, 4, 91, 173, 47, 15, 194, 352, 2, 44, 12, 33, 44, 2, 2, 2, 13, 144, 440, 38, 4, 64, 155, 15, 13, 80, 135, 9, 15, 49, 7, 4, 2, 302, 34, 2, 26, 6, 117, 2, 2, 13, 191, 377, 101, 2, 139, 11, 2, 7, 2, 345, 2, 4, 22, 152, 2, 4, 541, 599, 19, 6, 646, 2, 2, 2, 2, 83, 2, 393, 11, 2, 6, 2, 2, 2, 84, 2, 23, 2, 7, 2, 294, 112, 2, 34, 6, 666, 2, 6, 2, 125, 2, 2, 998, 2, 2, 4, 116, 9, 184, 52, 2, 17, 2, 9, 55, 163, 17, 29, 2, 4, 31, 2, 46, 13, 82, 40, 4, 139, 19, 2, 33, 4, 454, 169, 41, 55, 2, 54, 442, 2, 32, 15, 2, 2, 13, 191, 30, 4, 64, 31, 2, 13, 2, 104, 2, 7, 2, 9, 6, 777, 22, 964, 722, 39, 380, 8, 2, 87, 2, 189, 11, 2, 2, 33, 64, 2, 234, 196, 12, 115, 461, 357, 42, 753, 6, 965, 2, 7, 2, 106, 12, 17, 515, 17, 25, 70]\n",
      " [1, 2, 256, 34, 31, 7, 4, 91, 2, 2, 7, 4, 236, 2, 7, 14, 2, 5, 82, 31, 7, 4, 91, 2, 2, 2, 2, 46, 7, 2, 59, 9, 389, 9, 175, 173, 15, 59, 299, 4, 2, 2, 9, 4, 2, 5, 2, 7, 4, 298, 438, 10, 10, 2, 2, 9, 2, 5, 41, 658, 742, 217, 73, 2, 34, 530, 284, 5, 82, 735, 2, 2, 2, 2, 2, 7, 4, 2, 255, 47, 6, 254, 58, 19, 4, 2, 2, 7, 27, 31, 283, 155, 5, 2, 27, 2, 339, 4, 338, 577, 2, 2, 2, 2, 2, 47, 96, 99, 76, 873, 7, 41, 57, 2, 4, 65, 304, 6, 55, 821, 650, 23, 4, 2, 7, 6, 2, 11, 14, 20, 4, 64, 577, 47, 8, 276, 41, 113, 23, 2, 8, 459, 18, 4, 738, 7, 409, 50, 9, 210, 31, 11, 175, 223, 37, 2, 15, 243, 7, 2, 2, 9, 2, 4, 454, 7, 4, 20, 21, 17, 58, 2, 59, 630, 56, 2, 41, 2, 113, 58, 2, 8, 41, 223, 59, 60, 2, 41, 2, 89, 81, 25, 81, 27, 175, 251, 11, 5, 46, 5, 2, 2, 12, 15, 9, 51, 372, 81, 6, 176, 7, 51, 13, 683, 2, 157, 2, 75, 2, 75, 2, 75, 2, 75, 2, 75, 2, 75, 26, 4, 118, 369, 75, 26, 4, 2, 2, 49, 7, 178, 40, 199, 372, 11, 14, 20, 28, 4, 404, 2, 26, 4, 2, 2, 18, 4, 436, 223, 5, 82, 81, 32, 15, 2, 157, 15, 9, 2, 2, 5, 111, 372, 11, 263, 926, 111, 7, 178, 28, 460, 825, 143, 15, 868, 7, 113, 54, 263, 846, 559, 5, 2, 13, 28, 77, 50, 36, 43, 435, 99, 185, 13, 28, 348, 61, 846, 61, 2, 21, 13, 115, 2, 98, 17, 73, 17, 54, 13, 69, 8, 297, 68, 555, 5, 69, 8, 2, 11, 68, 2, 14, 20, 2, 4, 635, 7, 113, 382, 12, 9, 619, 21, 15, 9, 89, 113, 9, 33, 211, 742, 6, 2, 33, 2, 9, 2, 415, 37, 739, 8, 104, 15, 27, 157, 9, 53, 674, 74, 2, 334, 5, 47, 6, 55, 2, 2, 2, 2, 4, 372, 11, 27, 113, 29, 9, 24, 565, 195, 8, 2, 48, 25, 181, 8, 67, 52, 116, 5, 4, 635, 7, 113, 81, 24, 717, 14, 20, 514, 139, 4, 2, 582, 8, 2, 2, 5, 32, 4, 231, 7, 6, 2, 46, 7, 2, 2, 15, 13, 38, 2, 75, 26, 32, 2, 2, 514, 2, 742, 12, 9, 64, 34, 170, 2, 15, 25, 923, 15, 25, 26, 66, 170, 2, 742, 25, 28, 6, 2, 2, 21, 121, 9, 129, 483, 10, 10]\n",
      " ...,\n",
      " [1, 14, 390, 7, 2, 2, 285, 4, 123, 9, 44, 8, 130, 45, 840, 811, 5, 32, 609, 9, 2, 2, 11, 14, 390, 4, 2, 663, 721, 35, 2, 773, 884, 2, 8, 4, 2, 4, 2, 90, 39, 4, 2, 2, 54, 2, 29, 2, 11, 17, 6, 2, 5, 95, 83, 27, 2, 2, 29, 2, 2, 6, 2, 63, 484, 2, 41, 46, 5, 2, 2, 41, 95, 2, 2, 2, 51, 9, 317, 7, 4, 2, 2, 266, 39, 4, 2, 5, 560, 4, 2, 2, 159, 385, 516, 4, 2, 21, 112, 4, 671, 7, 31, 12, 43, 2, 90, 2, 266, 8, 2, 4, 85, 2, 5, 494, 8, 169, 5, 2, 90, 18, 147, 2, 2, 9, 11, 4, 2, 269, 8, 169, 2, 54, 5, 2, 140, 46, 83, 4, 890, 8, 169, 4, 2, 4, 2, 659, 98, 103, 68, 985, 4, 2, 923, 15, 6, 370, 2, 285, 54, 36, 79, 145, 8, 2, 269, 8, 985, 4, 2, 5, 103, 36, 2, 6, 6, 2, 825, 2, 2, 2, 2, 41, 2, 8, 847, 84, 46, 7, 4, 96, 38, 59, 70, 79, 8, 4, 2, 21, 36, 79, 68, 8, 522, 5, 2, 2, 5, 43, 54, 9, 44, 8, 79, 324, 58, 9, 2, 8, 121, 36, 721, 884, 2, 8, 4, 2, 2, 11, 5, 2, 5, 2, 21, 2, 9, 131, 11, 4, 2, 38, 2, 4, 2, 5, 2, 46, 7, 4, 2, 54, 2, 417, 266, 29, 191, 2, 9, 351, 5, 38, 9, 4, 671, 7, 289, 18, 150, 2, 14, 390, 16, 619, 16, 4, 7, 32, 7, 98, 13, 62, 119, 8, 28, 41, 671, 7, 2, 13, 66, 92, 104, 2, 144, 7, 435, 8, 4, 2, 88, 48, 59, 161, 586, 28, 556, 21, 2, 961, 4, 671, 7, 289, 295, 174, 5, 146, 654, 19, 4, 2, 2]\n",
      " [1, 13, 435, 83, 14, 22, 2, 2, 18, 6, 2, 2, 11, 405, 2, 7, 2, 2, 21, 51, 13, 188, 16, 53, 7, 6, 2, 2, 2, 19, 230, 99, 76, 662, 5, 24, 195, 206, 45, 788, 15, 14, 22, 16, 93, 23, 6, 352, 4, 2, 26, 2, 5, 862, 324, 137, 4, 116, 889, 6, 176, 8, 30, 2, 82, 4, 114, 2, 23, 6, 2, 7, 2, 6, 336, 5, 107, 2, 15, 2, 6, 2, 7, 2, 103, 880, 49, 2, 36, 216, 638, 6, 2, 2, 34, 6, 185, 250, 5, 41, 2, 5, 32, 14, 9, 579, 11, 2, 34, 4, 185, 250, 2, 2, 11, 35, 2, 45, 788, 15, 907, 2, 5, 2, 2, 197, 36, 71, 231, 142, 66, 2, 21, 466, 94, 118, 2, 2, 7, 609, 2, 9, 43, 99, 357, 8, 2, 4, 529, 4, 22, 2, 23, 18, 44, 2, 234, 5, 91, 7, 12, 2, 7, 357, 105, 2, 125, 357, 5, 196, 2, 414, 4, 64, 52, 155, 13, 28, 8, 135, 44, 4, 22, 9, 19, 2, 8, 4, 228, 63, 9, 52, 11, 2, 4, 277, 9, 4, 64, 85, 52, 155, 44, 4, 20, 5, 198, 64, 88, 45, 4, 236, 155, 15, 571, 13, 586, 386, 259, 2, 2, 14, 180, 50, 16, 76, 128, 2, 93, 11, 4, 2]\n",
      " [1, 2, 54, 13, 435, 8, 67, 14, 20, 33, 4, 2, 750, 11, 2, 13, 122, 24, 535, 76, 13, 435, 8, 14, 20, 64, 88, 13, 2, 2, 45, 6, 2, 20, 2, 30, 52, 18, 6, 462, 95, 13, 2, 180, 5, 296, 12, 5, 219, 138, 36, 2, 2, 2, 2, 8, 297, 2, 2, 29, 9, 242, 31, 7, 4, 2, 493, 23, 4, 194, 268, 76, 433, 11, 61, 652, 74, 2, 42, 2, 5, 47, 31, 194, 2, 8, 85, 102, 15, 2, 72, 8, 6, 189, 20, 12, 287, 2, 2, 17, 294, 37, 9, 406, 29, 47, 6, 483, 57, 551, 89, 2, 5, 948, 12, 9, 29, 764, 2, 142, 15, 2, 115, 127, 42, 739, 8, 123, 29, 764, 2, 5, 2, 151, 174, 199, 7, 98, 2, 63, 25, 80, 2, 48, 25, 67, 4, 20, 32, 11, 32, 6, 275, 585, 11, 61, 652, 74, 111, 2, 5, 12, 770, 72, 11, 6, 171, 771, 17, 11, 37, 2, 11, 4, 130]]\n",
      "length X_test:  25000\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import merge\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Input, Dropout, Convolution1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 1000\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "#print(len(X_train), 'train sequences')\n",
    "#print(len(X_test), 'test sequences')\n",
    "\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "print('y_train: \\n',y_train)\n",
    "print('length y_train: ', len(y_train))\n",
    "print('y_test: \\n',y_test)\n",
    "print('length y_test: ', len(y_test))\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "print('X_train: \\n',X_train)\n",
    "print('length X_train: ', len(X_train))\n",
    "print('X_test: \\n',X_test)\n",
    "print('length X_test: ', len(X_test))\n",
    "print('@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "#print (X_train[0])\n",
    "\n",
    "print(type(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X_train shape:\n",
      " (25000,)\n",
      "y_train shape:  (25000,)\n",
      "\n",
      " X_test shape:\n",
      " (25000,)\n",
      "y_test shape:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "#-----------------\n",
    "print(\"\\n X_train shape:\\n\",X_train.shape)\n",
    "print('y_train shape: ',y_train.shape)\n",
    "#----------------------------------\n",
    "print('\\n X_test shape:\\n', X_test.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "25000\n",
      "(25000, 80)\n",
      "(25000,)\n",
      "(25000, 80)\n",
      "(25000,)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "#print('X_train shape:', X_train.shape)\n",
    "#print('X_train', X_train)\n",
    "#print('X_test shape:', X_test.shape)\n",
    "#print('X_test',X_test)\n",
    "\n",
    "\n",
    "print(len(y_test))\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "#print(X_test)\n",
    "#print(type(X_test))\n",
    "\n",
    "\n",
    "print('Build model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X_train shape:\n",
      " (25000, 80) <type 'numpy.ndarray'>\n",
      "y_train shape:  (25000,)\n",
      "\n",
      " X_test shape:\n",
      " (25000, 80) <type 'numpy.ndarray'>\n",
      "y_test shape:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "#-----------------\n",
    "print(\"\\n X_train shape:\\n\",X_train.shape, type(X_train))\n",
    "print('y_train shape: ',y_train.shape)\n",
    "#----------------------------------\n",
    "print('\\n X_test shape:\\n', X_test.shape,type(X_test))\n",
    "print('y_test shape: ',y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(maxlen,))\n",
    "x = inputs\n",
    "x = Embedding(max_features, 128, dropout=0.2)(x)\n",
    "\n",
    "\n",
    "#--------- LSTM layer --------------\n",
    "y = inputs\n",
    "y = Embedding(max_features, 128, dropout=0.2)(y)\n",
    "y = LSTM(128, dropout_W=0.2, dropout_U=0.2)(y)\n",
    "\n",
    "#----Convolution Layer------\n",
    "x=Convolution1D(nb_filter=64, filter_length=3, border_mode='valid',activation='relu', subsample_length=1)(x)\n",
    "x=GlobalMaxPooling1D()(x)\n",
    "#---------------------------\n",
    "#x = Flatten()(x)\n",
    "\n",
    "\n",
    "x = merge([x,y], mode='concat')\n",
    "#-------- layer of 64 relu & dropout layer------\n",
    "x = Dense(64)(x)\n",
    "x = PReLU()(x) # Non-linearity\n",
    "#x=Dropout(0.5)(x)\n",
    "\n",
    "#-----------------------------------------------\n",
    "x = Dense(1)(x)\n",
    "predictions = Activation(\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=15,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
